{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronaldehido/BirdNET-colab/blob/main/RON_BirdNET_1_Inferencia(batch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwHjQq2rer5G"
      },
      "source": [
        "# 🐦**Inferencia con modelo personalizado CNN en BirdNET Analyzer** 🐦\n",
        "versión 3 (21-07-2025)\n",
        "\n",
        "\n",
        "### *Ron A. Fernández-Gómez - EPM SECIHTI* 🤓\n",
        "Este es un flujo de trabajo en Google Colab escrito en Python para ejecutar modelos personalizados basados en Redes Neuronales Convolucionales (CNNs) para detección y clasificación de vocalizaciones de fauna utilizando la herramienta BirdNET Analyzer para uso con Interfaz de línea de comando (CLI).\n",
        "Para mayores detalles sobre BirdNET Analyzer y usos del proyecto BirdNET consultar: https://github.com/birdnet-team/BirdNET-Analyzer\n",
        "\n",
        "\n",
        "##### *comentarios sobre optimización*\n",
        "Aunque los modelos compatibles con BirdNET Analyzer se generan en Tensorflow, algunos están en formato .tflite que pueden tener algunas limitaciones para optimizar procesos de inferencias basados en el uso de paralelización en GPU, delegando los procesos a la CPU. Por lo tanto en este flujo buscaremos trabajar en un entorno de ejecución de Colab con recursos disponibles en CPU. Se recomienda usar opciones de entorno que cuenten con la virtualización de varios procesadores CPU. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OwAcgq_lvoD"
      },
      "source": [
        "## Paqueterías y dependencias necesarias\n",
        "Estas dependencias facilitaran el funcionamiento del analizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tffhDQmjluDD"
      },
      "outputs": [],
      "source": [
        "!pip install ffmpeg\n",
        "!pip install librosa\n",
        "!pip install resampy\n",
        "!pip install tensorflow==2.15.0\n",
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHEVI-gipDtL"
      },
      "source": [
        "# 1. INFERENCIA: Deteccion de vocalizaciones por lotes\n",
        "Esta etapa corresponde a la ejecución de un modelo CNN por lotes. Permite ejecutar el modelo en una carpeta que contenga varios archivos de audio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZHxi4Tijev9"
      },
      "source": [
        "## *Conectar a Google Drive y definir rutas*\n",
        "Primero vincularemos Google Drive con lo que definirimos las rutas de acceso a los archivos de trabajo y de salida de resultados durante la sesión de trabajo. En el Drive tedremos los archivos a analizar y los modelos personalizados a ejecutar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KxbW_Wy0jeC8"
      },
      "outputs": [],
      "source": [
        "# Conectar con google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "audio_path = r'E:\\audiotest' #definir esta ruta '/ruta/a/la/carpeta/de/archivos'\n",
        "output_folder = r'E:\\Test_BirdNet-naiby\\restBN_r101_short\\rescolab' #definir esta ruta '/ruta/a/la/carpeta/donde/guardar/los/resultados'\n",
        "\n",
        "#Ruta al modelo (en caso de usar un modelo personalizado)\n",
        "my_model = r'E:\\CNN models wildmon\\V3\\renamegui\\WildMon-20spp-V3.0_Model_FP32.tflite' #definir esta ruta '/ruta/al/modelo/personalizado.tflite'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STNt9fy-fy-X"
      },
      "outputs": [],
      "source": [
        "#Rutas de entrada y salida\n",
        "audio_path = '/ruta/a/la/carpeta/de/archivos' #definir esta ruta '/ruta/a/la/carpeta/de/archivos'\n",
        "output_folder = '/ruta/a/la/carpeta/donde/guardar/los/resultados' #definir esta ruta '/ruta/a/la/carpeta/donde/guardar/los/resultados'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Ruta al modelo (en caso de usar un modelo personalizado)\n",
        "my_model = '/ruta/al/modelo/personalizado.tflite' #definir esta ruta '/ruta/al/modelo/personalizado.tflite'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbD9u8KbrQEP"
      },
      "source": [
        "## *Clonar BirdNET Analyzer*\n",
        "Clonamos el respositorio de BirdNET Analyzer en nuestro espacio de trabajo desde GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGsYI97CrPs0"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/birdnet-team/BirdNET-Analyzer.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs9jjg8R11Qh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d:\\GitHub\\EchoSonR\\BirdNET_running\\BirdNET-Analyzer\n"
          ]
        }
      ],
      "source": [
        "#se establece el nuevo directorio de trabajo donde estan las funciones\n",
        "%cd BirdNET-Analyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8jUL9wRp6iCX"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'d:\\\\GitHub\\\\EchoSonR\\\\BirdNET_running\\\\BirdNET-Analyzer'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# revisamos el directorio y confirmamos\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKsOg46cjiSj"
      },
      "source": [
        "### *Ejemplo de inferencia con un solo archivo de audio*\n",
        "Usamos un ejemplo incluido en BirdNET para hacer una prueba rápida de que la función corre correctamente. La prueba se usa corriendo el modelo base (GLOBAL V2.4, June 2023). El resultado se obtendrá como un archivo de texto en la carpeta de trabajo. Lo revisamos y verificamos que todo sea correcto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KR6RITWjGNe5"
      },
      "outputs": [],
      "source": [
        "#Hacemos una prueba rapida con un ejemplo incluido (archivo example) para verificar el funcionamiento correcto de la funcion \"analyze\"\n",
        "!python -m birdnet_analyzer.analyze birdnet_analyzer/example/ --slist birdnet_analyzer/example/species_list.txt --min_conf 0.5 --threads 4 --combine_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### *Inferencia en lote con modelo personalizado*\n",
        "Ejecutamos BirdNET sobre un directorio completo y ajustamos parametros adicionales segun nuestra necesidad, además incluimos un modelo entrenado personalizado. En caso de querer usar el modelo por defecto (GLOBAL) no se declara el argumento --classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Procesar una carpeta con archivos y el modelo personalizado, en este caso cargamos el modelo de WildMon dando la ruta del archivo\n",
        "# --classifier es la ruta al modelo personalizado, si no se especifica se usa el modelo por defecto (GLOBAL)\n",
        "!python -m birdnet_analyzer.analyze \\\n",
        "        --output \"{output_folder}\" \\\n",
        "        --classifier \"{my_model}\" \\\n",
        "        --min_conf 0.05 \\\n",
        "        --threads 6 \\\n",
        "        --b 3 \\\n",
        "        --combine_results \\\n",
        "        \"{audio_path}\"\n",
        "\n",
        "#usage: birdnet_analyzer.analyze [-h] [-o OUTPUT] [--fmin FMIN] [--fmax FMAX]\n",
        "#                                [--lat LAT] [--lon LON] [--week WEEK]\n",
        "#                                [--sf_thresh SF_THRESH] [--slist SLIST]\n",
        "#                                [--sensitivity SENSITIVITY]\n",
        "#                                [--overlap OVERLAP]\n",
        "#                                [--audio_speed AUDIO_SPEED] [-t THREADS]\n",
        "#                                [--min_conf MIN_CONF] [-l LOCALE]\n",
        "#                                [-b BATCH_SIZE]\n",
        "#                                [--rtype {table,audacity,kaleidoscope,csv} [{table,audacity,kaleidoscope,csv} ...]]\n",
        "#                                [--additional_columns {lat,lon,week,overlap,sensitivity,min_conf,species_list,model} [{lat,lon,week,overlap,sensitivity,min_conf,species_list,model} ...]]\n",
        "#                                [--combine_results] [-c CLASSIFIER]\n",
        "#                                [--skip_existing_results] [--top_n TOP_N]\n",
        "#                                [--merge_consecutive MERGE_CONSECUTIVE]\n",
        "#                                INPUT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx1KIWMV-mww"
      },
      "source": [
        "Fin."
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "authorship_tag": "ABX9TyPrFQ7Q4EGwkoJ4NFqtCtQe",
      "gpuType": "V28",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "scikit-maad",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
