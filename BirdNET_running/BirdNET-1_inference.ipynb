{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronaldehido/BirdNET-colab/blob/main/RON_BirdNET_1_Inferencia(batch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwHjQq2rer5G"
      },
      "source": [
        "# **Inferencia con modelo personalizado CNN en BirdNET Analyzer** \n",
        "versi贸n 3 (21-07-2025)\n",
        "\n",
        "\n",
        "### *Ron A. Fern谩ndez-G贸mez - EPM SECIHTI* \n",
        "Este es un flujo de trabajo en Google Colab escrito en Python para ejecutar modelos personalizados basados en Redes Neuronales Convolucionales (CNNs) para detecci贸n y clasificaci贸n de vocalizaciones de fauna utilizando la herramienta BirdNET Analyzer para uso con Interfaz de l铆nea de comando (CLI).\n",
        "Para mayores detalles sobre BirdNET Analyzer y usos del proyecto BirdNET consultar: https://github.com/birdnet-team/BirdNET-Analyzer\n",
        "\n",
        "\n",
        "##### *comentarios sobre optimizaci贸n*\n",
        "Aunque los modelos compatibles con BirdNET Analyzer se generan en Tensorflow, algunos est谩n en formato .tflite que pueden tener algunas limitaciones para optimizar procesos de inferencias basados en el uso de paralelizaci贸n en GPU, delegando los procesos a la CPU. Por lo tanto en este flujo buscaremos trabajar en un entorno de ejecuci贸n de Colab con recursos disponibles en CPU. Se recomienda usar opciones de entorno que cuenten con la virtualizaci贸n de varios procesadores CPU. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OwAcgq_lvoD"
      },
      "source": [
        "## Paqueter铆as y dependencias necesarias\n",
        "Estas dependencias facilitaran el funcionamiento del analizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tffhDQmjluDD"
      },
      "outputs": [],
      "source": [
        "!pip install ffmpeg\n",
        "!pip install librosa\n",
        "!pip install resampy\n",
        "!pip install tensorflow==2.15.0\n",
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHEVI-gipDtL"
      },
      "source": [
        "# 1. INFERENCIA: Deteccion de vocalizaciones por lotes\n",
        "Esta etapa corresponde a la ejecuci贸n de un modelo CNN por lotes. Permite ejecutar el modelo en una carpeta que contenga varios archivos de audio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZHxi4Tijev9"
      },
      "source": [
        "## *Conectar a Google Drive y definir rutas*\n",
        "Primero vincularemos Google Drive con lo que definirimos las rutas de acceso a los archivos de trabajo y de salida de resultados durante la sesi贸n de trabajo. En el Drive tedremos los archivos a analizar y los modelos personalizados a ejecutar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KxbW_Wy0jeC8"
      },
      "outputs": [],
      "source": [
        "# Conectar con google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "audio_path = r'E:\\audiotest' #definir esta ruta '/ruta/a/la/carpeta/de/archivos'\n",
        "output_folder = r'E:\\Test_BirdNet-naiby\\restBN_r101_short\\rescolab' #definir esta ruta '/ruta/a/la/carpeta/donde/guardar/los/resultados'\n",
        "\n",
        "#Ruta al modelo (en caso de usar un modelo personalizado)\n",
        "my_model = r'E:\\CNN models wildmon\\V3\\renamegui\\WildMon-20spp-V3.0_Model_FP32.tflite' #definir esta ruta '/ruta/al/modelo/personalizado.tflite'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STNt9fy-fy-X"
      },
      "outputs": [],
      "source": [
        "#Rutas de entrada y salida\n",
        "audio_path = '/ruta/a/la/carpeta/de/archivos' #definir esta ruta '/ruta/a/la/carpeta/de/archivos'\n",
        "output_folder = '/ruta/a/la/carpeta/donde/guardar/los/resultados' #definir esta ruta '/ruta/a/la/carpeta/donde/guardar/los/resultados'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Ruta al modelo (en caso de usar un modelo personalizado)\n",
        "my_model = '/ruta/al/modelo/personalizado.tflite' #definir esta ruta '/ruta/al/modelo/personalizado.tflite'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbD9u8KbrQEP"
      },
      "source": [
        "## *Clonar BirdNET Analyzer*\n",
        "Clonamos el respositorio de BirdNET Analyzer en nuestro espacio de trabajo desde GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGsYI97CrPs0"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/birdnet-team/BirdNET-Analyzer.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs9jjg8R11Qh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d:\\GitHub\\EchoSonR\\BirdNET_running\\BirdNET-Analyzer\n"
          ]
        }
      ],
      "source": [
        "#se establece el nuevo directorio de trabajo donde estan las funciones\n",
        "%cd BirdNET-Analyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8jUL9wRp6iCX"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'d:\\\\GitHub\\\\EchoSonR\\\\BirdNET_running\\\\BirdNET-Analyzer'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# revisamos el directorio y confirmamos\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKsOg46cjiSj"
      },
      "source": [
        "### *Ejemplo de inferencia con un solo archivo de audio*\n",
        "Usamos un ejemplo incluido en BirdNET para hacer una prueba r谩pida de que la funci贸n corre correctamente. La prueba se usa corriendo el modelo base (GLOBAL V2.4, June 2023). El resultado se obtendr谩 como un archivo de texto en la carpeta de trabajo. Lo revisamos y verificamos que todo sea correcto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KR6RITWjGNe5"
      },
      "outputs": [],
      "source": [
        "#Hacemos una prueba rapida con un ejemplo incluido (archivo example) para verificar el funcionamiento correcto de la funcion \"analyze\"\n",
        "!python -m birdnet_analyzer.analyze birdnet_analyzer/example/ --slist birdnet_analyzer/example/species_list.txt --min_conf 0.5 --threads 4 --combine_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### *Inferencia en lote con modelo personalizado*\n",
        "Ejecutamos BirdNET sobre un directorio completo y ajustamos parametros adicionales segun nuestra necesidad, adem谩s incluimos un modelo entrenado personalizado. En caso de querer usar el modelo por defecto (GLOBAL) no se declara el argumento --classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Procesar una carpeta con archivos y el modelo personalizado, en este caso cargamos el modelo de WildMon dando la ruta del archivo\n",
        "# --classifier es la ruta al modelo personalizado, si no se especifica se usa el modelo por defecto (GLOBAL)\n",
        "!python -m birdnet_analyzer.analyze \\\n",
        "        --output \"{output_folder}\" \\\n",
        "        --classifier \"{my_model}\" \\\n",
        "        --min_conf 0.05 \\\n",
        "        --threads 6 \\\n",
        "        --b 3 \\\n",
        "        --combine_results \\\n",
        "        \"{audio_path}\"\n",
        "\n",
        "#usage: birdnet_analyzer.analyze [-h] [-o OUTPUT] [--fmin FMIN] [--fmax FMAX]\n",
        "#                                [--lat LAT] [--lon LON] [--week WEEK]\n",
        "#                                [--sf_thresh SF_THRESH] [--slist SLIST]\n",
        "#                                [--sensitivity SENSITIVITY]\n",
        "#                                [--overlap OVERLAP]\n",
        "#                                [--audio_speed AUDIO_SPEED] [-t THREADS]\n",
        "#                                [--min_conf MIN_CONF] [-l LOCALE]\n",
        "#                                [-b BATCH_SIZE]\n",
        "#                                [--rtype {table,audacity,kaleidoscope,csv} [{table,audacity,kaleidoscope,csv} ...]]\n",
        "#                                [--additional_columns {lat,lon,week,overlap,sensitivity,min_conf,species_list,model} [{lat,lon,week,overlap,sensitivity,min_conf,species_list,model} ...]]\n",
        "#                                [--combine_results] [-c CLASSIFIER]\n",
        "#                                [--skip_existing_results] [--top_n TOP_N]\n",
        "#                                [--merge_consecutive MERGE_CONSECUTIVE]\n",
        "#                                INPUT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx1KIWMV-mww"
      },
      "source": [
        "Fin."
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "authorship_tag": "ABX9TyPrFQ7Q4EGwkoJ4NFqtCtQe",
      "gpuType": "V28",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "scikit-maad",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
