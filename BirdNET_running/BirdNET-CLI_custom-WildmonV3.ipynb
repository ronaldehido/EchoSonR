{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronaldehido/EchoSonR/blob/main/BirdNET_running/BirdNET-CLI_custom-WildmonV3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwHjQq2rer5G"
      },
      "source": [
        "# <img src=\"https://raw.githubusercontent.com/birdnet-team/BirdNET-Analyzer/refs/heads/main/docs/_static/birdnet_logo.png\" width=\"50\">**Inferencias con BirdNET-CLI sobre audios en Google Drive**<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/12/Google_Drive_icon_%282020%29.svg\" width=\"50\"> \n",
        "## **Inferencia con modelos personalizados  y caso Wildmon V3 y FLAT SIGMOIDS)**\n",
        "_versi칩n 1 (2025-07-25)_\n",
        "\n",
        "\n",
        "\n",
        "### *Ron A. Fern치ndez-G칩mez - EPM SECIHTI* 游뱁\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/17/Logotipo_SECIHTI_2025-2030.svg\" width=\"200\">\n",
        "\n",
        "Este es un flujo de trabajo en Google Colab escrito en Python para ejecutar clasificadores personalizados basados en Redes Neuronales Convolucionales (CNNs) para detecci칩n y clasificaci칩n de vocalizaciones de fauna utilizando la herramienta BirdNET Analyzer para uso con Interfaz de l칤nea de comando (CLI) y accediendo a archivos de audio alojados en Google Drive, Unidades Compartidas para trabajo colaborativo, asi como a partir de audios de otras fuentes locales.\n",
        "Para mayores detalles sobre BirdNET Analyzer y usos del proyecto BirdNET consultar: https://github.com/birdnet-team/BirdNET-Analyzer\n",
        "\n",
        "\n",
        "##### **_Comentarios sobre clasificador personalizado Wildmon V3_**\n",
        "La versi칩n V3 del clasificador genera outputs que distribuyen los scores en un rango entre 0.5 y 0.7, para ampliar la distribuci칩n a toda la escala de los confidence scores, se evita la aplicaci칩n de la sigmoides sobre las predicciones. Para esto fue necesario modificar el codigo fuente por lo que el analizador utilizado es un repositorio clonado modificado.\n",
        "El cambio especifico para saltar las sigmoides se hizo en el archivo config.py aplicando el operador booleano False en el argumento APPLY_SIGMOID (https://github.com/birdnet-team/BirdNET-Analyzer/blob/main/birdnet_analyzer/config.py#L85)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHEVI-gipDtL"
      },
      "source": [
        "# 1. INFERENCIA: Deteccion de vocalizaciones por lotes\n",
        "Esta etapa corresponde a la ejecuci칩n de un modelo CNN por lotes. Permite ejecutar el modelo en una carpeta que contenga varios archivos de audio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OwAcgq_lvoD"
      },
      "source": [
        "## Paqueter칤as y dependencias necesarias\n",
        "Estas dependencias facilitaran el funcionamiento del analizador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tffhDQmjluDD"
      },
      "outputs": [],
      "source": [
        "!pip install ffmpeg\n",
        "!pip install librosa\n",
        "!pip install resampy\n",
        "!pip install tensorflow==2.15.0\n",
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZHxi4Tijev9"
      },
      "source": [
        "## *Conectar a Google Drive y definir rutas*\n",
        "Primero vincularemos Google Drive con lo que definirimos las rutas de acceso a los archivos de trabajo y de salida de resultados durante la sesi칩n de trabajo. En el Drive deber치n estar los archivos de audio a analizar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KxbW_Wy0jeC8"
      },
      "outputs": [],
      "source": [
        "# Conectar con google drive y montar la unidad\n",
        "!pip install google-colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STNt9fy-fy-X"
      },
      "outputs": [],
      "source": [
        "#Rutas de entrada y salida a tu Google Drive\n",
        "audio_path = '/ruta/a/la/carpeta/de/archivos' # definir la ruta al directorio con los archivos de audio\n",
        "output_folder = '/ruta/a/la/carpeta/donde/guardar/los/resultados' # definir la ruta al directorio donde se guardar치n los resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# establecer el nombre del sitio y/o muestreo\n",
        "site_name = 'nombre_del_sitio'  # <--- Cambia esto al nombre del sitio que est치s analizando, por ejemplo, 'R405-202408'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modelo personalizado\n",
        "En este caso usaremos el modelo V3 de WildMon. Comparto el modelo el cual esta etiquetado de forma que pueda ser reconocido por el analyzador de BirdNET y tambien se reconozcan las especies. Ser치 necesario clonar el repositorio de EchoSonR para acceder al Model-Zoo donde adicionalmente encontrar치 otras versiones de este y otros modelos pre-entrenados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### clonamos el Model-Zoo de EchoSonR para acceder al clasificador personalizado\n",
        "!mkdir -p /content/Model-Zoo\n",
        "%cd /content/Model-Zoo\n",
        "!git init\n",
        "!git remote add origin https://github.com/ronaldehido/EchoSonR.git\n",
        "!git config core.sparseCheckout true\n",
        "!echo \"BirdNET_running/Model-Zoo/*\" > .git/info/sparse-checkout\n",
        "!git pull origin main\n",
        "!mv BirdNET_running/Model-Zoo/* ./\n",
        "!rm -rf BirdNET_running\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ruta al modelo (en caso de usar un modelo personalizado)\n",
        "# modelo V3 de Wildmon\n",
        "my_model = '/content/Model-Zoo/WildMon/Wildmon-V3/WildMon-20spp-V3.0_Model_FP32.tflite' #definir la ruta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbD9u8KbrQEP"
      },
      "source": [
        "### *Clonar BirdNET Analyzer*\n",
        "Clonamos el respositorio de BirdNET Analyzer en nuestro espacio de trabajo desde GitHub. Esto nos permite ejecutar el analizador y sus funciones. Aqu칤 presento dos opciones de repositorios clonados. 1) la primera opciones es clonar el repositorio directamente desde el GitHub del BirdNET-Team. La opcion 2) es un repositorio clonado de BirdNET a la fecha de 2024.07.25 pero modificado por Ron A. Fern치ndez-G칩mez para que no se apliquen las sigmoides sobre las predicciones. Esto es 칰til para que el modelo V3 de Wildmon pueda generar predicciones con scores distribuidos en toda la escala (0 a 1). Escoge la opci칩n que corresponda en tu caso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**OPCI칍N 1)** Clonar BirdNET-Analyzer desde el respositorio original del BirdNET Team"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGsYI97CrPs0"
      },
      "outputs": [],
      "source": [
        "# OPCI칍N 1) Clonar BirdNET-Analyzer desde el respositorio original del BirdNET Team\n",
        "!git clone https://github.com/birdnet-team/BirdNET-Analyzer.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**OPCI칍N 2)** Clonar la version modificada de BirdNET-Analyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPCI칍N 2) Clonar la version modificada de BirdNET-Analyzer\n",
        "!git clone https://github.com/ronaldehido/EchoSonR/tree/main/BirdNET_running/BirdNET-repos/BirdNET-Analyzer_Mod_runWMV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs9jjg8R11Qh"
      },
      "outputs": [],
      "source": [
        "# se establece el nuevo directorio de trabajo donde estan las funciones\n",
        "# para la version modificada de BirdNET-Analyzer ser치:\n",
        "%cd BirdNET-Analyzer_Mod_runWMV3\n",
        "\n",
        "# Para la version original de BirdNET-Analyzer usar:\n",
        "# %cd BirdNET-Analyzer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKsOg46cjiSj"
      },
      "source": [
        "### *Ejemplo de inferencia con un solo archivo de audio*\n",
        "Usamos un ejemplo incluido en BirdNET para hacer una prueba r치pida de que la funci칩n corre correctamente. La prueba se usa corriendo el modelo base (GLOBAL V2.4). El resultado se obtendr치 como un archivo de texto en la carpeta de trabajo. Lo revisamos y verificamos que todo sea correcto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KR6RITWjGNe5"
      },
      "outputs": [],
      "source": [
        "#Hacemos una prueba rapida con un ejemplo incluido (archivo example) para verificar el funcionamiento correcto de la funcion \"analyze\"\n",
        "!python -m birdnet_analyzer.analyze birdnet_analyzer/example/ --slist birdnet_analyzer/example/species_list.txt --min_conf 0.5 --threads 4 --combine_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### *Inferencia en lote con modelo personalizado*\n",
        "Ejecutamos BirdNET sobre un directorio completo y ajustamos parametros adicionales segun nuestra necesidad, adem치s incluimos un modelo entrenado personalizado. En caso de querer usar el modelo por defecto (GLOBAL) no se declara el argumento --classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Procesar una carpeta con archivos y el modelo personalizado, en este caso cargamos el modelo de WildMon dando la ruta del archivo\n",
        "# --classifier es la ruta al modelo personalizado, si no se especifica se usa el modelo por defecto (GLOBAL)\n",
        "# --min_conf aqu칤 lo ajuste al m칤nimo para obtener el total de detecciones, si se quiere un umbral mayor se puede ajustar\n",
        "!python -m birdnet_analyzer.analyze \\\n",
        "        --output \"{output_folder}\" \\\n",
        "        --classifier \"{my_model}\" \\\n",
        "        --min_conf 0.0001 \\\n",
        "        --threads 2 \\\n",
        "        --b 1 \\\n",
        "        --combine_results \\\n",
        "        \"{audio_path}\"\n",
        "\n",
        "# Otros argumentos que se pueden usar:\n",
        "# usage: birdnet_analyzer.analyze [-h] [-o OUTPUT] [--fmin FMIN] [--fmax FMAX]\n",
        "#                                [--lat LAT] [--lon LON] [--week WEEK]\n",
        "#                                [--sf_thresh SF_THRESH] [--slist SLIST]\n",
        "#                                [--sensitivity SENSITIVITY]\n",
        "#                                [--overlap OVERLAP]\n",
        "#                                [--audio_speed AUDIO_SPEED] [-t THREADS]\n",
        "#                                [--min_conf MIN_CONF] [-l LOCALE]\n",
        "#                                [-b BATCH_SIZE]\n",
        "#                                [--rtype {table,audacity,kaleidoscope,csv} [{table,audacity,kaleidoscope,csv} ...]]\n",
        "#                                [--additional_columns {lat,lon,week,overlap,sensitivity,min_conf,species_list,model} [{lat,lon,week,overlap,sensitivity,min_conf,species_list,model} ...]]\n",
        "#                                [--combine_results] [-c CLASSIFIER]\n",
        "#                                [--skip_existing_results] [--top_n TOP_N]\n",
        "#                                [--merge_consecutive MERGE_CONSECUTIVE]\n",
        "#                                INPUT\n",
        "\n",
        "\n",
        "# Mostrar resumen al final\n",
        "import os\n",
        "\n",
        "print(\"\\n ======== RESUMEN DE LA PREDICI칍N: ========\")\n",
        "print(f\"游늬 Modelo usado: {os.path.basename(my_model)}\")\n",
        "print(f\"游늭 Carpeta de resultados: {output_folder}\")\n",
        "print(f\"游늸 Sitio analizado: {site_name}\")\n",
        "print(f\"游꿢 Valor de confianza m칤nimo: {min_conf}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Fin.**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "authorship_tag": "ABX9TyPrFQ7Q4EGwkoJ4NFqtCtQe",
      "gpuType": "V28",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "scikit-maad",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
